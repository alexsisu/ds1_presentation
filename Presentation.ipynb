{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/alexsisu/ds1_presentation\n",
    "\n",
    "Decision trees T&T.\n",
    "\n",
    "Data Science problem context:\n",
    "There are some aspects that you need to be aware of when talking about applying a datascience problem in the industry.\n",
    "1. -understanding of the domain\n",
    "2. -understanding of the algorithms that you plan to apply\n",
    "3. -technicalities: libraries, platform\n",
    "4. -feature engineering:\n",
    "5. -data transformation pipeline\n",
    "6. -costs: \n",
    "\t\t- time\n",
    "\t\t- hardware \n",
    "\t\t- income/ROI\n",
    "\t\t- is a slow/high accuracy solution preferable to a fast/medium-low accuracy solution?\n",
    "\n",
    "1. What is a decision tree.\n",
    "\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. \n",
    "http://scikit-learn.org/stable/modules/tree.html#tree\n",
    "    \n",
    "Solve: classification and regression problems.\n",
    "Classification: the modeled response is discrete domain.\n",
    "Regression: the response is in continous domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] ['setosa' 'versicolor' 'virginica']\n",
      "[ 5.1  3.5  1.4  0.2] 0\n",
      "[ 4.9  3.   1.4  0.2] 0\n",
      "[ 4.7  3.2  1.3  0.2] 0\n",
      "[ 4.6  3.1  1.5  0.2] 0\n",
      "[ 5.   3.6  1.4  0.2] 0\n",
      "[ 5.4  3.9  1.7  0.4] 0\n",
      "[ 4.6  3.4  1.4  0.3] 0\n",
      "[ 5.   3.4  1.5  0.2] 0\n",
      "[ 4.4  2.9  1.4  0.2] 0\n",
      "[ 4.9  3.1  1.5  0.1] 0\n",
      "[ 5.4  3.7  1.5  0.2] 0\n",
      "[ 4.8  3.4  1.6  0.2] 0\n",
      "[ 4.8  3.   1.4  0.1] 0\n",
      "[ 4.3  3.   1.1  0.1] 0\n",
      "[ 5.8  4.   1.2  0.2] 0\n",
      "[ 5.7  4.4  1.5  0.4] 0\n",
      "[ 5.4  3.9  1.3  0.4] 0\n",
      "[ 5.1  3.5  1.4  0.3] 0\n",
      "[ 5.7  3.8  1.7  0.3] 0\n",
      "[ 5.1  3.8  1.5  0.3] 0\n",
      "[ 5.4  3.4  1.7  0.2] 0\n",
      "[ 5.1  3.7  1.5  0.4] 0\n",
      "[ 4.6  3.6  1.   0.2] 0\n",
      "[ 5.1  3.3  1.7  0.5] 0\n",
      "[ 4.8  3.4  1.9  0.2] 0\n",
      "[ 5.   3.   1.6  0.2] 0\n",
      "[ 5.   3.4  1.6  0.4] 0\n",
      "[ 5.2  3.5  1.5  0.2] 0\n",
      "[ 5.2  3.4  1.4  0.2] 0\n",
      "[ 4.7  3.2  1.6  0.2] 0\n",
      "[ 4.8  3.1  1.6  0.2] 0\n",
      "[ 5.4  3.4  1.5  0.4] 0\n",
      "[ 5.2  4.1  1.5  0.1] 0\n",
      "[ 5.5  4.2  1.4  0.2] 0\n",
      "[ 4.9  3.1  1.5  0.1] 0\n",
      "[ 5.   3.2  1.2  0.2] 0\n",
      "[ 5.5  3.5  1.3  0.2] 0\n",
      "[ 4.9  3.1  1.5  0.1] 0\n",
      "[ 4.4  3.   1.3  0.2] 0\n",
      "[ 5.1  3.4  1.5  0.2] 0\n",
      "[ 5.   3.5  1.3  0.3] 0\n",
      "[ 4.5  2.3  1.3  0.3] 0\n",
      "[ 4.4  3.2  1.3  0.2] 0\n",
      "[ 5.   3.5  1.6  0.6] 0\n",
      "[ 5.1  3.8  1.9  0.4] 0\n",
      "[ 4.8  3.   1.4  0.3] 0\n",
      "[ 5.1  3.8  1.6  0.2] 0\n",
      "[ 4.6  3.2  1.4  0.2] 0\n",
      "[ 5.3  3.7  1.5  0.2] 0\n",
      "[ 5.   3.3  1.4  0.2] 0\n",
      "[ 7.   3.2  4.7  1.4] 1\n",
      "[ 6.4  3.2  4.5  1.5] 1\n",
      "[ 6.9  3.1  4.9  1.5] 1\n",
      "[ 5.5  2.3  4.   1.3] 1\n",
      "[ 6.5  2.8  4.6  1.5] 1\n",
      "[ 5.7  2.8  4.5  1.3] 1\n",
      "[ 6.3  3.3  4.7  1.6] 1\n",
      "[ 4.9  2.4  3.3  1. ] 1\n",
      "[ 6.6  2.9  4.6  1.3] 1\n",
      "[ 5.2  2.7  3.9  1.4] 1\n",
      "[ 5.   2.   3.5  1. ] 1\n",
      "[ 5.9  3.   4.2  1.5] 1\n",
      "[ 6.   2.2  4.   1. ] 1\n",
      "[ 6.1  2.9  4.7  1.4] 1\n",
      "[ 5.6  2.9  3.6  1.3] 1\n",
      "[ 6.7  3.1  4.4  1.4] 1\n",
      "[ 5.6  3.   4.5  1.5] 1\n",
      "[ 5.8  2.7  4.1  1. ] 1\n",
      "[ 6.2  2.2  4.5  1.5] 1\n",
      "[ 5.6  2.5  3.9  1.1] 1\n",
      "[ 5.9  3.2  4.8  1.8] 1\n",
      "[ 6.1  2.8  4.   1.3] 1\n",
      "[ 6.3  2.5  4.9  1.5] 1\n",
      "[ 6.1  2.8  4.7  1.2] 1\n",
      "[ 6.4  2.9  4.3  1.3] 1\n",
      "[ 6.6  3.   4.4  1.4] 1\n",
      "[ 6.8  2.8  4.8  1.4] 1\n",
      "[ 6.7  3.   5.   1.7] 1\n",
      "[ 6.   2.9  4.5  1.5] 1\n",
      "[ 5.7  2.6  3.5  1. ] 1\n",
      "[ 5.5  2.4  3.8  1.1] 1\n",
      "[ 5.5  2.4  3.7  1. ] 1\n",
      "[ 5.8  2.7  3.9  1.2] 1\n",
      "[ 6.   2.7  5.1  1.6] 1\n",
      "[ 5.4  3.   4.5  1.5] 1\n",
      "[ 6.   3.4  4.5  1.6] 1\n",
      "[ 6.7  3.1  4.7  1.5] 1\n",
      "[ 6.3  2.3  4.4  1.3] 1\n",
      "[ 5.6  3.   4.1  1.3] 1\n",
      "[ 5.5  2.5  4.   1.3] 1\n",
      "[ 5.5  2.6  4.4  1.2] 1\n",
      "[ 6.1  3.   4.6  1.4] 1\n",
      "[ 5.8  2.6  4.   1.2] 1\n",
      "[ 5.   2.3  3.3  1. ] 1\n",
      "[ 5.6  2.7  4.2  1.3] 1\n",
      "[ 5.7  3.   4.2  1.2] 1\n",
      "[ 5.7  2.9  4.2  1.3] 1\n",
      "[ 6.2  2.9  4.3  1.3] 1\n",
      "[ 5.1  2.5  3.   1.1] 1\n",
      "[ 5.7  2.8  4.1  1.3] 1\n",
      "[ 6.3  3.3  6.   2.5] 2\n",
      "[ 5.8  2.7  5.1  1.9] 2\n",
      "[ 7.1  3.   5.9  2.1] 2\n",
      "[ 6.3  2.9  5.6  1.8] 2\n",
      "[ 6.5  3.   5.8  2.2] 2\n",
      "[ 7.6  3.   6.6  2.1] 2\n",
      "[ 4.9  2.5  4.5  1.7] 2\n",
      "[ 7.3  2.9  6.3  1.8] 2\n",
      "[ 6.7  2.5  5.8  1.8] 2\n",
      "[ 7.2  3.6  6.1  2.5] 2\n",
      "[ 6.5  3.2  5.1  2. ] 2\n",
      "[ 6.4  2.7  5.3  1.9] 2\n",
      "[ 6.8  3.   5.5  2.1] 2\n",
      "[ 5.7  2.5  5.   2. ] 2\n",
      "[ 5.8  2.8  5.1  2.4] 2\n",
      "[ 6.4  3.2  5.3  2.3] 2\n",
      "[ 6.5  3.   5.5  1.8] 2\n",
      "[ 7.7  3.8  6.7  2.2] 2\n",
      "[ 7.7  2.6  6.9  2.3] 2\n",
      "[ 6.   2.2  5.   1.5] 2\n",
      "[ 6.9  3.2  5.7  2.3] 2\n",
      "[ 5.6  2.8  4.9  2. ] 2\n",
      "[ 7.7  2.8  6.7  2. ] 2\n",
      "[ 6.3  2.7  4.9  1.8] 2\n",
      "[ 6.7  3.3  5.7  2.1] 2\n",
      "[ 7.2  3.2  6.   1.8] 2\n",
      "[ 6.2  2.8  4.8  1.8] 2\n",
      "[ 6.1  3.   4.9  1.8] 2\n",
      "[ 6.4  2.8  5.6  2.1] 2\n",
      "[ 7.2  3.   5.8  1.6] 2\n",
      "[ 7.4  2.8  6.1  1.9] 2\n",
      "[ 7.9  3.8  6.4  2. ] 2\n",
      "[ 6.4  2.8  5.6  2.2] 2\n",
      "[ 6.3  2.8  5.1  1.5] 2\n",
      "[ 6.1  2.6  5.6  1.4] 2\n",
      "[ 7.7  3.   6.1  2.3] 2\n",
      "[ 6.3  3.4  5.6  2.4] 2\n",
      "[ 6.4  3.1  5.5  1.8] 2\n",
      "[ 6.   3.   4.8  1.8] 2\n",
      "[ 6.9  3.1  5.4  2.1] 2\n",
      "[ 6.7  3.1  5.6  2.4] 2\n",
      "[ 6.9  3.1  5.1  2.3] 2\n",
      "[ 5.8  2.7  5.1  1.9] 2\n",
      "[ 6.8  3.2  5.9  2.3] 2\n",
      "[ 6.7  3.3  5.7  2.5] 2\n",
      "[ 6.7  3.   5.2  2.3] 2\n",
      "[ 6.3  2.5  5.   1.9] 2\n",
      "[ 6.5  3.   5.2  2. ] 2\n",
      "[ 6.2  3.4  5.4  2.3] 2\n",
      "[ 5.9  3.   5.1  1.8] 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"872pt\" height=\"642pt\"\n",
       " viewBox=\"0.00 0.00 871.83 642.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 638)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-638 867.8306,-638 867.8306,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M526.3569,-634C526.3569,-634 387.3979,-634 387.3979,-634 381.3979,-634 375.3979,-628 375.3979,-622 375.3979,-622 375.3979,-568 375.3979,-568 375.3979,-562 381.3979,-556 387.3979,-556 387.3979,-556 526.3569,-556 526.3569,-556 532.3569,-556 538.3569,-562 538.3569,-568 538.3569,-568 538.3569,-622 538.3569,-622 538.3569,-628 532.3569,-634 526.3569,-634\"/>\n",
       "<text text-anchor=\"start\" x=\"383.3877\" y=\"-618.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) ≤ 2.45</text>\n",
       "<text text-anchor=\"start\" x=\"416.5933\" y=\"-604.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.6667</text>\n",
       "<text text-anchor=\"start\" x=\"411.1553\" y=\"-590.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 150</text>\n",
       "<text text-anchor=\"start\" x=\"397.1382\" y=\"-576.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"412.3276\" y=\"-562.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M426.7837,-513C426.7837,-513 330.9712,-513 330.9712,-513 324.9712,-513 318.9712,-507 318.9712,-501 318.9712,-501 318.9712,-461 318.9712,-461 318.9712,-455 324.9712,-449 330.9712,-449 330.9712,-449 426.7837,-449 426.7837,-449 432.7837,-449 438.7837,-455 438.7837,-461 438.7837,-461 438.7837,-501 438.7837,-501 438.7837,-507 432.7837,-513 426.7837,-513\"/>\n",
       "<text text-anchor=\"start\" x=\"350.2725\" y=\"-497.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"337.0483\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"326.9243\" y=\"-469.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"334.3276\" y=\"-455.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M430.0343,-555.7677C422.4491,-544.6817 414.1823,-532.5994 406.5494,-521.4436\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"409.3933,-519.4019 400.8578,-513.1252 403.6161,-523.3547 409.3933,-519.4019\"/>\n",
       "<text text-anchor=\"middle\" x=\"396.2506\" y=\"-533.497\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M602.3958,-520C602.3958,-520 469.3591,-520 469.3591,-520 463.3591,-520 457.3591,-514 457.3591,-508 457.3591,-508 457.3591,-454 457.3591,-454 457.3591,-448 463.3591,-442 469.3591,-442 469.3591,-442 602.3958,-442 602.3958,-442 608.3958,-442 614.3958,-448 614.3958,-454 614.3958,-454 614.3958,-508 614.3958,-508 614.3958,-514 608.3958,-520 602.3958,-520\"/>\n",
       "<text text-anchor=\"start\" x=\"465.1187\" y=\"-504.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.75</text>\n",
       "<text text-anchor=\"start\" x=\"507.2725\" y=\"-490.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"490.1553\" y=\"-476.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n",
       "<text text-anchor=\"start\" x=\"480.0313\" y=\"-462.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"482\" y=\"-448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M484.0648,-555.7677C490.0853,-547.0798 496.5298,-537.7801 502.7571,-528.794\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"505.8209,-530.5176 508.64,-520.3046 500.0673,-526.5304 505.8209,-530.5176\"/>\n",
       "<text text-anchor=\"middle\" x=\"513.1009\" y=\"-540.7034\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.898039\" stroke=\"#000000\" d=\"M491.3569,-406C491.3569,-406 352.3979,-406 352.3979,-406 346.3979,-406 340.3979,-400 340.3979,-394 340.3979,-394 340.3979,-340 340.3979,-340 340.3979,-334 346.3979,-328 352.3979,-328 352.3979,-328 491.3569,-328 491.3569,-328 497.3569,-328 503.3569,-334 503.3569,-340 503.3569,-340 503.3569,-394 503.3569,-394 503.3569,-400 497.3569,-406 491.3569,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"348.3877\" y=\"-390.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) ≤ 4.95</text>\n",
       "<text text-anchor=\"start\" x=\"385.4863\" y=\"-376.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.168</text>\n",
       "<text text-anchor=\"start\" x=\"380.0483\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 54</text>\n",
       "<text text-anchor=\"start\" x=\"369.9243\" y=\"-348.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"368\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M496.6451,-441.7677C487.5094,-432.632 477.6972,-422.8198 468.2844,-413.407\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"470.7281,-410.9009 461.1821,-406.3046 465.7783,-415.8506 470.7281,-410.9009\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.976471\" stroke=\"#000000\" d=\"M719.3569,-406C719.3569,-406 580.3979,-406 580.3979,-406 574.3979,-406 568.3979,-400 568.3979,-394 568.3979,-394 568.3979,-340 568.3979,-340 568.3979,-334 574.3979,-328 580.3979,-328 580.3979,-328 719.3569,-328 719.3569,-328 725.3569,-328 731.3569,-334 731.3569,-340 731.3569,-340 731.3569,-394 731.3569,-394 731.3569,-400 725.3569,-406 719.3569,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"576.3877\" y=\"-390.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) ≤ 4.85</text>\n",
       "<text text-anchor=\"start\" x=\"609.5933\" y=\"-376.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0425</text>\n",
       "<text text-anchor=\"start\" x=\"608.0483\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n",
       "<text text-anchor=\"start\" x=\"597.9243\" y=\"-348.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"start\" x=\"600.2759\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M575.1098,-441.7677C584.2454,-432.632 594.0577,-422.8198 603.4705,-413.407\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"605.9766,-415.8506 610.5728,-406.3046 601.0268,-410.9009 605.9766,-415.8506\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.980392\" stroke=\"#000000\" d=\"M265.3958,-292C265.3958,-292 132.3591,-292 132.3591,-292 126.3591,-292 120.3591,-286 120.3591,-280 120.3591,-280 120.3591,-226 120.3591,-226 120.3591,-220 126.3591,-214 132.3591,-214 132.3591,-214 265.3958,-214 265.3958,-214 271.3958,-214 277.3958,-220 277.3958,-226 277.3958,-226 277.3958,-280 277.3958,-280 277.3958,-286 271.3958,-292 265.3958,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"128.1187\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.65</text>\n",
       "<text text-anchor=\"start\" x=\"158.5933\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0408</text>\n",
       "<text text-anchor=\"start\" x=\"157.0483\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 48</text>\n",
       "<text text-anchor=\"start\" x=\"146.9243\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 47, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"145\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M345.4455,-327.9272C325.7649,-317.8662 304.4614,-306.9757 284.3538,-296.6965\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"285.7067,-293.4572 275.2095,-292.0218 282.5204,-299.69 285.7067,-293.4572\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M488.3958,-292C488.3958,-292 355.3591,-292 355.3591,-292 349.3591,-292 343.3591,-286 343.3591,-280 343.3591,-280 343.3591,-226 343.3591,-226 343.3591,-220 349.3591,-214 355.3591,-214 355.3591,-214 488.3958,-214 488.3958,-214 494.3958,-214 500.3958,-220 500.3958,-226 500.3958,-226 500.3958,-280 500.3958,-280 500.3958,-286 494.3958,-292 488.3958,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"351.1187\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.55</text>\n",
       "<text text-anchor=\"start\" x=\"381.5933\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.4444</text>\n",
       "<text text-anchor=\"start\" x=\"383.9414\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"373.8174\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"372.2759\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M421.8774,-327.7677C421.8774,-319.6172 421.8774,-310.9283 421.8774,-302.4649\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"425.3775,-302.3046 421.8774,-292.3046 418.3775,-302.3047 425.3775,-302.3046\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M111.6326,-171C111.6326,-171 12.1223,-171 12.1223,-171 6.1223,-171 .1223,-165 .1223,-159 .1223,-159 .1223,-119 .1223,-119 .1223,-113 6.1223,-107 12.1223,-107 12.1223,-107 111.6326,-107 111.6326,-107 117.6326,-107 123.6326,-113 123.6326,-119 123.6326,-119 123.6326,-159 123.6326,-159 123.6326,-165 117.6326,-171 111.6326,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"33.2725\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"20.0483\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 47</text>\n",
       "<text text-anchor=\"start\" x=\"9.9243\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 47, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151.7298,-213.7677C137.7541,-202.1383 122.4609,-189.4125 108.5175,-177.81\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.4096,-174.8312 100.484,-171.1252 105.9321,-180.2119 110.4096,-174.8312\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M244.5807,-171C244.5807,-171 153.1741,-171 153.1741,-171 147.1741,-171 141.1741,-165 141.1741,-159 141.1741,-159 141.1741,-119 141.1741,-119 141.1741,-113 147.1741,-107 153.1741,-107 153.1741,-107 244.5807,-107 244.5807,-107 250.5807,-107 256.5807,-113 256.5807,-119 256.5807,-119 256.5807,-159 256.5807,-159 256.5807,-165 250.5807,-171 244.5807,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"170.2725\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"160.9414\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"150.8174\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"149.2759\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.8774,-213.7677C198.8774,-203.3338 198.8774,-192.0174 198.8774,-181.4215\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"202.3775,-181.1252 198.8774,-171.1252 195.3775,-181.1252 202.3775,-181.1252\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M377.5807,-171C377.5807,-171 286.1741,-171 286.1741,-171 280.1741,-171 274.1741,-165 274.1741,-159 274.1741,-159 274.1741,-119 274.1741,-119 274.1741,-113 280.1741,-107 286.1741,-107 286.1741,-107 377.5807,-107 377.5807,-107 383.5807,-107 389.5807,-113 389.5807,-119 389.5807,-119 389.5807,-159 389.5807,-159 389.5807,-165 383.5807,-171 377.5807,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"303.2725\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"293.9414\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"283.8174\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 3]</text>\n",
       "<text text-anchor=\"start\" x=\"282.2759\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M390.9045,-213.7677C382.0667,-202.573 372.4267,-190.3624 363.5478,-179.1158\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"366.183,-176.8053 357.2394,-171.1252 360.6888,-181.1428 366.183,-176.8053\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M561.9673,-178C561.9673,-178 419.7876,-178 419.7876,-178 413.7876,-178 407.7876,-172 407.7876,-166 407.7876,-166 407.7876,-112 407.7876,-112 407.7876,-106 413.7876,-100 419.7876,-100 419.7876,-100 561.9673,-100 561.9673,-100 567.9673,-100 573.9673,-106 573.9673,-112 573.9673,-112 573.9673,-166 573.9673,-166 573.9673,-172 567.9673,-178 561.9673,-178\"/>\n",
       "<text text-anchor=\"start\" x=\"415.8325\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sepal length (cm) ≤ 6.95</text>\n",
       "<text text-anchor=\"start\" x=\"450.5933\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.4444</text>\n",
       "<text text-anchor=\"start\" x=\"452.9414\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"442.8174\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"437\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M445.6233,-213.7677C450.8275,-205.1694 456.3945,-195.9718 461.7812,-187.072\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"464.904,-188.672 467.0878,-178.3046 458.9155,-185.0473 464.904,-188.672\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M471.6326,-64C471.6326,-64 372.1223,-64 372.1223,-64 366.1223,-64 360.1223,-58 360.1223,-52 360.1223,-52 360.1223,-12 360.1223,-12 360.1223,-6 366.1223,0 372.1223,0 372.1223,0 471.6326,0 471.6326,0 477.6326,0 483.6326,-6 483.6326,-12 483.6326,-12 483.6326,-52 483.6326,-52 483.6326,-58 477.6326,-64 471.6326,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"393.2725\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"383.9414\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"373.8174\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"368\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M465.5762,-99.7647C459.9223,-90.9971 453.9128,-81.678 448.2179,-72.8469\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"451.0138,-70.7242 442.6528,-64.2169 445.1309,-74.5178 451.0138,-70.7242\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M604.5807,-64C604.5807,-64 513.1741,-64 513.1741,-64 507.1741,-64 501.1741,-58 501.1741,-52 501.1741,-52 501.1741,-12 501.1741,-12 501.1741,-6 507.1741,0 513.1741,0 513.1741,0 604.5807,0 604.5807,0 610.5807,0 616.5807,-6 616.5807,-12 616.5807,-12 616.5807,-52 616.5807,-52 616.5807,-58 610.5807,-64 604.5807,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"530.2725\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"520.9414\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"510.8174\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"509.2759\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M515.812,-99.7647C521.384,-90.9971 527.3064,-81.678 532.9187,-72.8469\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"535.9934,-74.534 538.4032,-64.2169 530.0855,-70.7795 535.9934,-74.534\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M714.2193,-292C714.2193,-292 585.5356,-292 585.5356,-292 579.5356,-292 573.5356,-286 573.5356,-280 573.5356,-280 573.5356,-226 573.5356,-226 573.5356,-220 579.5356,-214 585.5356,-214 585.5356,-214 714.2193,-214 714.2193,-214 720.2193,-214 726.2193,-220 726.2193,-226 726.2193,-226 726.2193,-280 726.2193,-280 726.2193,-286 720.2193,-292 714.2193,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"581.4565\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sepal width (cm) ≤ 3.1</text>\n",
       "<text text-anchor=\"start\" x=\"609.5933\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.4444</text>\n",
       "<text text-anchor=\"start\" x=\"611.9414\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"601.8174\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"600.2759\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M649.8774,-327.7677C649.8774,-319.6172 649.8774,-310.9283 649.8774,-302.4649\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"653.3775,-302.3046 649.8774,-292.3046 646.3775,-302.3047 653.3775,-302.3046\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M851.7837,-285C851.7837,-285 755.9712,-285 755.9712,-285 749.9712,-285 743.9712,-279 743.9712,-273 743.9712,-273 743.9712,-233 743.9712,-233 743.9712,-227 749.9712,-221 755.9712,-221 755.9712,-221 851.7837,-221 851.7837,-221 857.7837,-221 863.7837,-227 863.7837,-233 863.7837,-233 863.7837,-273 863.7837,-273 863.7837,-279 857.7837,-285 851.7837,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"775.2725\" y=\"-269.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"762.0483\" y=\"-255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 43</text>\n",
       "<text text-anchor=\"start\" x=\"751.9243\" y=\"-241.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 43]</text>\n",
       "<text text-anchor=\"start\" x=\"754.2759\" y=\"-227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>12&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M702.8755,-327.7677C718.879,-315.9209 736.4195,-302.9364 752.3272,-291.1606\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"754.5252,-293.8881 760.4802,-285.1252 750.3604,-288.2619 754.5252,-293.8881\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M695.5807,-171C695.5807,-171 604.1741,-171 604.1741,-171 598.1741,-171 592.1741,-165 592.1741,-159 592.1741,-159 592.1741,-119 592.1741,-119 592.1741,-113 598.1741,-107 604.1741,-107 604.1741,-107 695.5807,-107 695.5807,-107 701.5807,-107 707.5807,-113 707.5807,-119 707.5807,-119 707.5807,-159 707.5807,-159 707.5807,-165 701.5807,-171 695.5807,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"621.2725\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"611.9414\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"601.8174\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"600.2759\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M649.8774,-213.7677C649.8774,-203.3338 649.8774,-192.0174 649.8774,-181.4215\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"653.3775,-181.1252 649.8774,-171.1252 646.3775,-181.1252 653.3775,-181.1252\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M836.6326,-171C836.6326,-171 737.1223,-171 737.1223,-171 731.1223,-171 725.1223,-165 725.1223,-159 725.1223,-159 725.1223,-119 725.1223,-119 725.1223,-113 731.1223,-107 737.1223,-107 737.1223,-107 836.6326,-107 836.6326,-107 842.6326,-107 848.6326,-113 848.6326,-119 848.6326,-119 848.6326,-159 848.6326,-159 848.6326,-165 842.6326,-171 836.6326,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"758.2725\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"748.9414\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"738.8174\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"733\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M697.0251,-213.7677C711.0008,-202.1383 726.294,-189.4125 740.2374,-177.81\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"742.8227,-180.2119 748.2708,-171.1252 738.3453,-174.8312 742.8227,-180.2119\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11a7cfeb8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "print(iris.feature_names,iris.target_names)\n",
    "for i in range(0,len(iris.data)):\n",
    "    print(iris.data[i],iris.target[i])\n",
    "\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree: Another simple example: titanic+ feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752542372881\n",
      "Pclass 0.11497333407\n",
      "Sex 0.293204696479\n",
      "Age 0.238330752017\n",
      "SibSp 0.0619787054849\n",
      "Parch 0.0136880865557\n",
      "Fare 0.245392416253\n",
      "Embarked 0.0324320091414\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "\n",
    "def harmonize_data(titanic):\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "    titanic[\"Age\"].median()\n",
    "\n",
    "    titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "\n",
    "    return titanic\n",
    "\n",
    "\n",
    "train = pd.read_csv('../datasets/titanic_training.csv', dtype={\"Age\": np.float64}, )\n",
    "data = harmonize_data(train)\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[predictors],\n",
    "                                                    data[\"Survived\"],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "alg = DecisionTreeClassifier(random_state=1)\n",
    "alg.fit(X_train, y_train)\n",
    "\n",
    "predicted = alg.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, predicted))\n",
    "\n",
    "for feature_and_importance in zip(predictors, alg.feature_importances_):\n",
    "    print(feature_and_importance[0], feature_and_importance[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the criterias for choosing nodes in a decision tree.\n",
    "    - \"how does the model know at what value to split the top node\"?\n",
    "\n",
    "    - https://stackoverflow.com/questions/1859554/what-is-entropy-and-information-gain\n",
    "\n",
    "    -  http://www.inf.ed.ac.uk/teaching/courses/iaml/2011/slides/dt.pdf\n",
    "\n",
    "    - https://datascience.stackexchange.com/questions/10228/gini-impurity-vs-entropy\n",
    "    \n",
    "    The decision tree is built in a top-down fashion, but the question is how do you choose which attribute\n",
    "    to split at each node? The answer is find the feature that best splits the target class into\n",
    "    the purest possible children nodes (ie: nodes that don't contain a mix of both male and female,\n",
    "    rather pure nodes with only one class).\n",
    "\n",
    "    This measure of purity is called the information. It represents the expected amount of information\n",
    "    that would be needed to specify whether a new instance (first-name) should be classified male or female,\n",
    "     given the example that reached the node. We calculate it based on the number of male and female classes at the node.\n",
    "\n",
    "    Entropy on the other hand is a measure of impurity (the opposite). It is defined for a binary class with values a/b as:\n",
    "\n",
    "    Entropy = - p(a)*log(p(a)) - p(b)*log(p(b))\n",
    "    This binary entropy function is depicted in the figure below (random variable can take one of two values). It reaches its maximum when the probability is p=1/2, meaning that p(X=a)=0.5 or similarlyp(X=b)=0.5 having a 50%/50% chance of being either a or b (uncertainty is at a maximum). The entropy function is at zero minimum when probability is p=1 or p=0 with complete certainty (p(X=a)=1 or p(X=a)=0 respectively, latter implies p(X=b)=1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest: Another simple example: titanic+ feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy:  0.806779661017\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "import copy\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "\n",
    "def harmonize_data(titanic):\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "    titanic[\"Age\"].median()\n",
    "\n",
    "    titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "\n",
    "    return titanic\n",
    "\n",
    "\n",
    "original_data = pd.read_csv('../datasets/titanic_training.csv', dtype={\"Age\": np.float64}, )\n",
    "data = harmonize_data(original_data)\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[predictors], \n",
    "                                                    data[\"Survived\"], \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)\n",
    "\n",
    "alg = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_estimators=10,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "\n",
    "alg.fit(X_train, y_train)\n",
    "\n",
    "predicted_y = alg.predict(X_test)\n",
    "print(\"RandomForest accuracy: \", accuracy_score(y_test, predicted_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "- a collection of trees\n",
    "- Advantages:\n",
    "    - few tuning parameters\n",
    "    - dont need to standardize the data\n",
    "    - build in cross validation\n",
    "    - low bias\n",
    "    - big variance\n",
    "    - prone to overfitting\n",
    "\n",
    "Parameters:\n",
    "    - number of trees\n",
    "    - number of fetaures to consider on each split\n",
    "    - depth of the trees\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest: we have the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1298508491, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1013994432, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=550290313, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1791095845, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=2135392491, splitter='best')\n",
      "Selected RandomForest subtrees accuracy:  0.786440677966\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "\n",
    "for estimator in alg.estimators_:\n",
    "    individual_prediction = estimator.predict(X_train)\n",
    "    performing_score = accuracy_score(y_train, individual_prediction)\n",
    "    model_list.append((estimator, performing_score))\n",
    "\n",
    "model_list = sorted(model_list, key=lambda p: p[1], reverse=True)\n",
    "\n",
    "# select the best 5 estimators\n",
    "selected_models = [p[0] for p in model_list[:5]]\n",
    "for selected_model in selected_models:\n",
    "    print(selected_model)\n",
    "\n",
    "new_rf = copy.copy(alg)\n",
    "new_rf.estimators_ = selected_models\n",
    "\n",
    "new_prediction = new_rf.predict(X_test)\n",
    "print(\"Selected RandomForest subtrees accuracy: \", accuracy_score(y_test, new_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tip: \n",
    "    - Select only the best performing trees\n",
    "    - Use multiple models and just select the best performing trees\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 Accuracy score: 0.820338983051\n",
      "Model 1 Accuracy score: 0.806779661017\n",
      "Model 2 Accuracy score: 0.84406779661\n",
      "Model 3 Accuracy score: 0.816949152542\n",
      "Model 4 Accuracy score: 0.8\n",
      "Model 5 Accuracy score: 0.803389830508\n",
      "Model 6 Accuracy score: 0.833898305085\n",
      "Model 7 Accuracy score: 0.796610169492\n",
      "Model 8 Accuracy score: 0.796610169492\n",
      "Model 9 Accuracy score: 0.813559322034\n",
      "Model 10 Accuracy score: 0.806779661017\n",
      "Model 11 Accuracy score: 0.786440677966\n",
      "Model 12 Accuracy score: 0.810169491525\n",
      "Model 13 Accuracy score: 0.8\n",
      "Model 14 Accuracy score: 0.813559322034\n",
      "Model 15 Accuracy score: 0.823728813559\n",
      "Model 16 Accuracy score: 0.820338983051\n",
      "Model 17 Accuracy score: 0.816949152542\n",
      "Model 18 Accuracy score: 0.816949152542\n",
      "Model 19 Accuracy score: 0.786440677966\n",
      "Model 20 Accuracy score: 0.840677966102\n",
      "Model 21 Accuracy score: 0.827118644068\n",
      "Model 22 Accuracy score: 0.8\n",
      "Model 23 Accuracy score: 0.827118644068\n",
      "Model 24 Accuracy score: 0.813559322034\n",
      "Model 25 Accuracy score: 0.827118644068\n",
      "Model 26 Accuracy score: 0.813559322034\n",
      "Model 27 Accuracy score: 0.803389830508\n",
      "Model 28 Accuracy score: 0.806779661017\n",
      "Model 29 Accuracy score: 0.803389830508\n",
      "Final model accuracy: 0.827118644068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "import copy\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "\n",
    "def harmonize_data(titanic):\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "    titanic[\"Age\"].median()\n",
    "\n",
    "    titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "\n",
    "    return titanic\n",
    "\n",
    "\n",
    "original_data = pd.read_csv('../datasets/titanic_training.csv', dtype={\"Age\": np.float64}, )\n",
    "data = harmonize_data(original_data)\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[predictors], data[\"Survived\"], test_size=0.33, random_state=42)\n",
    "\n",
    "original_list = []\n",
    "selected_trees = []\n",
    "nr_of_models = 30\n",
    "nr_estimators = 10\n",
    "\n",
    "for i in range(0, nr_of_models):\n",
    "    alg = RandomForestClassifier(\n",
    "        random_state=i,\n",
    "        n_estimators=nr_estimators,\n",
    "        min_samples_split=4,\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "\n",
    "    alg.fit(X_train, y_train)\n",
    "    original_list.append(alg)\n",
    "\n",
    "    predicted_y = alg.predict(X_test)\n",
    "    print(\"Model\", i, \"Accuracy score:\", accuracy_score(y_test, predicted_y))\n",
    "\n",
    "    for estimator in alg.estimators_:\n",
    "        individual_prediction = estimator.predict(X_test)\n",
    "        performing_score = accuracy_score(y_test, individual_prediction)\n",
    "        selected_trees.append((estimator, performing_score))\n",
    "\n",
    "selected_trees = sorted(selected_trees, key=lambda p: p[1], reverse=True)\n",
    "\n",
    "selected_models = [p[0] for p in selected_trees[:int((nr_of_models * nr_estimators * 2) / 3)]]\n",
    "# print(selected_models)\n",
    "\n",
    "new_forest = copy.copy(original_list[0])\n",
    "new_forest.estimators_ = selected_models\n",
    "\n",
    "new_prediction = new_forest.predict(X_test)\n",
    "print(\"Final model accuracy:\",accuracy_score(y_test, new_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest vs Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET SIZE: 978\n",
      "TEST DATASET SIZE: 482\n",
      "AVERAGE PRICE: SalePrice    180921.19589\n",
      "dtype: float64\n",
      "============ALL FEATURES=============\n",
      "RF Error: 31610.376632926025\n",
      "LR Error: 37471.77220509491\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics.regression import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "base_dataset_folder = \"~/.kaggle/competitions/house-prices-advanced-regression-techniques\"\n",
    "train_file_path = os.path.join(base_dataset_folder, \"train.csv\")\n",
    "\n",
    "data = pd.read_csv(train_file_path)\n",
    "\n",
    "target_column = [\"SalePrice\"]\n",
    "\n",
    "predictor_columns = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
    "                     'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
    "                     'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                     'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "                     'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "                     'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                     'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
    "                     'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
    "                     'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
    "                     'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "                     'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
    "                     'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
    "                     'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
    "                     'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                     'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
    "                     'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "                     'SaleCondition']\n",
    "\n",
    "\n",
    "def do_harmonization(original, prColumns, targetColumns):\n",
    "    dd = original.copy()\n",
    "    dd.fillna(0)\n",
    "    for col in prColumns:\n",
    "        if str(dd[col].dtype).lower() in [\"object\", \"string\"]:\n",
    "            dd[col] = LabelEncoder().fit_transform(dd[col].apply(str))\n",
    "        dd[col] = dd[col].fillna(dd[col].median())\n",
    "    dd[targetColumns] = dd[targetColumns]\n",
    "    return dd\n",
    "\n",
    "\n",
    "df = do_harmonization(data, predictor_columns, target_column)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[predictor_columns],\n",
    "                                                    df[target_column],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(\"TRAIN DATASET SIZE:\", len(X_train))\n",
    "print(\"TEST DATASET SIZE:\", len(X_test))\n",
    "print(\"AVERAGE PRICE:\", df[target_column].mean())\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train[predictor_columns], y_train)\n",
    "\n",
    "predicted = rf.predict(X_test[predictor_columns])\n",
    "\n",
    "print(\"============ALL FEATURES=============\")\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"RF Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted = lr.predict(X_test)\n",
    "print(\"LR Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of feature importance, and retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id       feature  importance\n",
      "0    1    MSSubClass    0.001954\n",
      "1    2      MSZoning    0.000534\n",
      "2    3   LotFrontage    0.005174\n",
      "3    4       LotArea    0.018370\n",
      "4    5        Street    0.000015\n",
      "5    6         Alley    0.002003\n",
      "6    7      LotShape    0.001449\n",
      "7    8   LandContour    0.003677\n",
      "8    9     Utilities    0.000000\n",
      "9   10     LotConfig    0.000830\n",
      "10  11     LandSlope    0.000246\n",
      "11  12  Neighborhood    0.008447\n",
      "12  13    Condition1    0.000321\n",
      "13  14    Condition2    0.000009\n",
      "14  15      BldgType    0.000151\n",
      "15  16    HouseStyle    0.003172\n",
      "16  17   OverallQual    0.504800\n",
      "17  18   OverallCond    0.003665\n",
      "18  19     YearBuilt    0.019896\n",
      "19  20  YearRemodAdd    0.009683\n",
      "============SELECTED FEATURES=============\n",
      "RF Error: 32931.82233785607\n",
      "LR Error: 35668.70917289232\n"
     ]
    }
   ],
   "source": [
    "feat_imp_df = pd.DataFrame({'id': range(1, len(rf.feature_importances_) + 1)})\n",
    "feat_imp_df['feature'] = predictor_columns\n",
    "feat_imp_df['importance'] = rf.feature_importances_\n",
    "\n",
    "columns_with_features = list(zip(predictor_columns, rf.feature_importances_))\n",
    "columns_with_features.sort(key=lambda x: x[1], reverse=True)\n",
    "print(feat_imp_df.head(20))\n",
    "\n",
    "nr_of_features = len(columns_with_features)\n",
    "\n",
    "print(\"============SELECTED FEATURES=============\")\n",
    "selected_features = [p[0] for p in columns_with_features[0:int(nr_of_features / 1.5)]]\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "\n",
    "predicted = rf.predict(X_test[selected_features])\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"RF Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train[selected_features], y_train)\n",
    "\n",
    "predicted = lr.predict(X_test[selected_features])\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"LR Error:\", sqrt(mean_squared_error(y_test, predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===============================OKA============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET SIZE: 978\n",
      "TEST DATASET SIZE: 482\n",
      "AVERAGE PRICE: SalePrice    180921.19589\n",
      "dtype: float64\n",
      "LR Error: 37471.77220509491\n",
      "============ALL FEATURES=============\n",
      "RF Error: 31154.61861789053\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics.regression import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "base_dataset_folder = \"~/.kaggle/competitions/house-prices-advanced-regression-techniques\"\n",
    "train_file_path = os.path.join(base_dataset_folder, \"train.csv\")\n",
    "\n",
    "data = pd.read_csv(train_file_path)\n",
    "target_column = [\"SalePrice\"]\n",
    "predictor_columns = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
    "                     'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
    "                     'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                     'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "                     'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "                     'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                     'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
    "                     'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
    "                     'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
    "                     'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "                     'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
    "                     'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
    "                     'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
    "                     'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                     'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
    "                     'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "                     'SaleCondition']\n",
    "\n",
    "\n",
    "def do_harmonization(original, prColumns, targetColumns):\n",
    "    dd = original.copy()\n",
    "    dd.fillna(0)\n",
    "    for col in prColumns:\n",
    "        if str(dd[col].dtype).lower() in [\"object\", \"string\"]:\n",
    "            dd[col] = LabelEncoder().fit_transform(dd[col].apply(str))\n",
    "        dd[col] = dd[col].fillna(dd[col].median())\n",
    "    dd[target_column] = dd[targetColumns]\n",
    "    return dd\n",
    "\n",
    "\n",
    "df = do_harmonization(data, predictor_columns, target_column)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[predictor_columns], df[target_column], test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(\"TRAIN DATASET SIZE:\", len(X_train))\n",
    "print(\"TEST DATASET SIZE:\", len(X_test))\n",
    "print(\"AVERAGE PRICE:\", df[target_column].mean())\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted = lr.predict(X_test)\n",
    "print(\"LR Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "nr_of_models = 10\n",
    "collected_scores = np.zeros((1, len(y_test)))\n",
    "for i in range(0, nr_of_models):\n",
    "    rf = RandomForestRegressor(random_state=i + 1)\n",
    "    rf.fit(X_train[predictor_columns], y_train)\n",
    "    predicted = rf.predict(X_test[predictor_columns])\n",
    "    collected_scores = collected_scores + predicted\n",
    "\n",
    "collected_scores = collected_scores / (float(nr_of_models))\n",
    "\n",
    "print(\"============ALL FEATURES=============\")\n",
    "print(\"RF Error:\", sqrt(mean_squared_error(y_test, collected_scores[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Optimization using:\n",
    "- feature selection\n",
    "- multiple models\n",
    "- sub trees selection\n",
    "- compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET SIZE: 978\n",
      "TEST DATASET SIZE: 482\n",
      "AVERAGE PRICE: SalePrice    180921.19589\n",
      "dtype: float64\n",
      "============ALL FEATURES=============\n",
      "LR Error: 37471.77220509491\n",
      "RF OKA Error: 31154.61861789053\n",
      "============BEGIN PERFORMING FEATURE SELECTION=============\n",
      "============END PERFORMING FEATURE SELECTION=============\n",
      "['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageArea', '1stFlrSF', 'BsmtFinSF1', 'GarageCars', 'BsmtQual', 'LotArea', 'YearRemodAdd']\n",
      "============MODELS USING SELECTED FEATURES=============\n",
      "ONE LR Selected Features Error: 35983.01118207054\n",
      "ONE RF Selected Feature  Error: 31766.848021809576\n",
      "============SELECTED FEATURES OKA LR an RF =============\n",
      "LR OKA Error: 35983.01118207054\n",
      "RF OKA Error: 30901.482297572562\n",
      "============SELECTED FEATURES OKA RF with sub trees selection =============\n",
      "LR Selected Features Error: 35983.01118207054\n",
      "Selected a nr of:  50  out of  100\n",
      "RF OKA with subtree selection Error: 30815.860138074237\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics.regression import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "base_dataset_folder = \"~/.kaggle/competitions/house-prices-advanced-regression-techniques\"\n",
    "train_file_path = os.path.join(base_dataset_folder, \"train.csv\")\n",
    "\n",
    "data = pd.read_csv(train_file_path)\n",
    "nr_of_models = 10\n",
    "target_column = [\"SalePrice\"]\n",
    "\n",
    "\n",
    "predictor_columns = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
    "                     'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
    "                     'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                     'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "                     'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "                     'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                     'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
    "                     'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
    "                     'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
    "                     'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "                     'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
    "                     'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
    "                     'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
    "                     'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                     'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
    "                     'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "                     'SaleCondition']\n",
    "\n",
    "\n",
    "def do_harmonization(original, prColumns, targetColumns):\n",
    "    dd = original.copy()\n",
    "    dd.fillna(0)\n",
    "    for col in prColumns:\n",
    "#        print(\"Processing\", col)\n",
    "        if str(dd[col].dtype).lower() in [\"object\", \"string\"]:\n",
    "            dd[col] = LabelEncoder().fit_transform(dd[col].apply(str))\n",
    "        dd[col] = dd[col].fillna(dd[col].median())\n",
    "#        dd[col] = StandardScaler().fit_transform(dd[col].fillna(dd[col].median()))\n",
    "#        dd[col] = Normalizer().fit_transform(dd[col].fillna(dd[col].median()).reshape(1, -1))[0]\n",
    "        \n",
    "    dd[targetColumns] = dd[targetColumns] \n",
    "#    dd[targetColumns] =np.log(dd[targetColumns])\n",
    "    return dd\n",
    "\n",
    "\n",
    "df = do_harmonization(data, predictor_columns, target_column)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[predictor_columns], df[target_column], test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(\"TRAIN DATASET SIZE:\", len(X_train))\n",
    "print(\"TEST DATASET SIZE:\", len(X_test))\n",
    "print(\"AVERAGE PRICE:\", df[target_column].mean())\n",
    "\n",
    "print(\"============ALL FEATURES=============\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted = lr.predict(X_test)\n",
    "print(\"LR Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "collected_scores = np.zeros((1, len(y_test)))\n",
    "for i in range(0, nr_of_models):\n",
    "    rf = RandomForestRegressor(random_state=i + 1)\n",
    "    rf.fit(X_train[predictor_columns], y_train)\n",
    "    predicted = rf.predict(X_test[predictor_columns])\n",
    "    collected_scores = collected_scores + predicted\n",
    "\n",
    "collected_scores = collected_scores / (float(nr_of_models))\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"RF OKA Error:\", sqrt(mean_squared_error(y_test, collected_scores[0])))\n",
    "\n",
    "\n",
    "\n",
    "print(\"============BEGIN PERFORMING FEATURE SELECTION=============\")\n",
    "columns_with_features = list(zip(predictor_columns, rf.feature_importances_))\n",
    "columns_with_features.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"============END PERFORMING FEATURE SELECTION=============\")\n",
    "nr_of_features = len(columns_with_features)\n",
    "\n",
    "selected_features = [p[0] for p in columns_with_features[0:int(nr_of_features / 1.5)]]\n",
    "print(selected_features[:10])\n",
    "print(\"============MODELS USING SELECTED FEATURES=============\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train[selected_features], y_train)\n",
    "\n",
    "predicted = lr.predict(X_test[selected_features])\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"ONE LR Selected Features Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "\n",
    "predicted = rf.predict(X_test[selected_features])\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"ONE RF Selected Feature  Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "print(\"============SELECTED FEATURES OKA LR an RF =============\")\n",
    "\n",
    "collected_scores = np.zeros((1, len(y_test)))\n",
    "for i in range(0, nr_of_models):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train[selected_features], y_train)\n",
    "    predicted = lr.predict(X_test[selected_features])\n",
    "    collected_scores = collected_scores + predicted\n",
    "\n",
    "collected_scores = collected_scores / (float(nr_of_models))\n",
    "print(\"LR OKA Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "collected_scores = np.zeros((1, len(y_test)))\n",
    "for i in range(0, nr_of_models):\n",
    "    rf = RandomForestRegressor(random_state=i + 1)\n",
    "    rf.fit(X_train[selected_features], y_train)\n",
    "    predicted = rf.predict(X_test[selected_features])\n",
    "    collected_scores = collected_scores + predicted\n",
    "\n",
    "collected_scores = collected_scores / (float(nr_of_models))\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"RF OKA Error:\",\n",
    "      sqrt(mean_squared_error(y_test, collected_scores[0])))  # collected_scores[0] because is a list of lists\n",
    "\n",
    "print(\"============SELECTED FEATURES OKA RF with sub trees selection =============\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train[selected_features], y_train)\n",
    "\n",
    "predicted = lr.predict(X_test[selected_features])\n",
    "\n",
    "# print(mean_absolute_error(y_test, predicted))\n",
    "print(\"LR Selected Features Error:\", sqrt(mean_squared_error(y_test, predicted)))\n",
    "\n",
    "selected_trees = []\n",
    "\n",
    "collected_scores = np.zeros((1, len(y_test)))\n",
    "for i in range(0, nr_of_models):\n",
    "    rf = RandomForestRegressor(random_state=i + 1)\n",
    "    rf.fit(X_train[selected_features], y_train)\n",
    "    predicted = rf.predict(X_test[selected_features])\n",
    "    for estimator in rf.estimators_:\n",
    "        individual_prediction = estimator.predict(X_train[selected_features])\n",
    "        performing_score = sqrt(mean_squared_error(y_train, individual_prediction))\n",
    "        selected_trees.append((estimator, performing_score))\n",
    "\n",
    "selected_trees = sorted(selected_trees, key=lambda p: p[1], reverse=False)\n",
    "\n",
    "selected_trees2 = selected_trees[0:int(len(selected_trees) * 0.5)]\n",
    "\n",
    "print(\"Selected a nr of: \", len(selected_trees2), \" out of \", len(selected_trees))\n",
    "\n",
    "collected_scores = np.zeros((1, len(y_test)))\n",
    "for tuple_est in selected_trees2:\n",
    "    estimator = tuple_est[0]\n",
    "    predicted = estimator.predict(X_test[selected_features])\n",
    "    collected_scores = collected_scores + predicted\n",
    "\n",
    "collected_scores = collected_scores / (float(len(selected_trees2)))\n",
    "\n",
    "print(\"RF OKA with subtree selection Error:\", sqrt(mean_squared_error(y_test, collected_scores[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tip:\n",
    "    - Ensemble modeling:\n",
    "        - feed the results from the previous model\n",
    "        - train another model with them\n",
    "        - use another model that takes training data as input from your "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shmen Error: 28855.134557692432\n"
     ]
    }
   ],
   "source": [
    "collective_df = pd.DataFrame({'param': range(1, len(X_train) + 1)})\n",
    "counter = 0\n",
    "fcols = []\n",
    "for tuple_est in selected_trees2:\n",
    "    counter += 1\n",
    "    estimator = tuple_est[0]\n",
    "    predicted = estimator.predict(X_train[selected_features])\n",
    "    collective_df[\"col\" + str(counter)] = predicted\n",
    "    fcols.append(\"col\" + str(counter))\n",
    "\n",
    "shmenModel = Ridge()\n",
    "shmenModel.fit(collective_df[fcols], y_train)\n",
    "\n",
    "to_predict_df = pd.DataFrame({'id': range(1, len(X_test) + 1)})\n",
    "counter = 0\n",
    "fcols = []\n",
    "for tuple_est in selected_trees2:\n",
    "    counter += 1\n",
    "    estimator = tuple_est[0]\n",
    "    predicted = estimator.predict(X_test[selected_features])\n",
    "    to_predict_df[\"col\" + str(counter)] = predicted\n",
    "    fcols.append(\"col\" + str(counter))\n",
    "\n",
    "predicted = shmenModel.predict(to_predict_df[fcols])\n",
    "\n",
    "print(\"Shmen Error:\", sqrt(mean_squared_error(y_test, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
